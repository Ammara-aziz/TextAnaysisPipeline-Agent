{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%pip install --quiet -U  langchain langchain-google-genai  langgraph"
      ],
      "metadata": {
        "id": "JH-LjVlJO0IO"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "google_api_key = userdata.get('GEMINI_API_KEY')\n"
      ],
      "metadata": {
        "id": "b7GfhheDOrmU"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "# Initialize an instance of the ChatGoogleGenerativeAI with specific parameters\n",
        "llm: ChatGoogleGenerativeAI = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-1.5-flash\",  # Specify the model to use\n",
        "    api_key=google_api_key,     # Provide the Google API key for authentication\n",
        ")"
      ],
      "metadata": {
        "id": "uM6JGxsnNcii"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "9C9z5wNjhwlI"
      },
      "outputs": [],
      "source": [
        "from typing_extensions import TypedDict\n",
        "from typing import List\n",
        "\n",
        "class TextAnalysisState(TypedDict):\n",
        "  text : str\n",
        "  classification : str\n",
        "  entities : List[str]\n",
        "  summary : str\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Nodes\n",
        "  * classification\n",
        "  * entities\n",
        "  * summary"
      ],
      "metadata": {
        "id": "7b8RK-qJ6BmG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# \"NODE 1\"     Text_Classify"
      ],
      "metadata": {
        "id": "HxmT8yg3mdXR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# node 1    classification\n",
        "\n",
        "def text_classify(state: TextAnalysisState) -> TextAnalysisState:\n",
        "  print('--classification--', state)\n",
        "  text : str = state['text']\n",
        "  prompt : str = f\"\"\"\n",
        "      Text will be given as input\n",
        "      Analyze the text and categorize it into one of the following domains:\n",
        "      NEWS, BLOG, RESEARCH, PRODUCT REVIEWS, ACADEMIC ESSAYS, PRESENTATIONS, or EMAIL COMMUNICATIONS.\n",
        "      Return the classification type.\n",
        "      Text: {text}\n",
        "\"\"\"\n",
        "\n",
        "  output = llm.invoke(prompt.format(text=text))\n",
        "  state['classification'] = output.content.strip()\n",
        "  return state\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "caxf3Wrj6A9i"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Node 2 -->"
      ],
      "metadata": {
        "id": "aMeVL-MOQrhv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# node 2    Entities Extraction\n",
        "\n",
        "def entities_extraction(state : TextAnalysisState) -> TextAnalysisState:\n",
        "  print('--Classification--', state)\n",
        "  text : str = state['text']\n",
        "  classification : str = state['classification']\n",
        "\n",
        "  prompt : str = f\"\"\"\n",
        "  You will be given Text as input.\n",
        "  Extract entities present in text i.e names, locations, organizations, dates, and any significant terms that contribute to the main theme.\n",
        "  Your job is to just return the entities present in json i.e entities  {{\"entities\": [\"zia khan lives in karachi\"]}}  entity1 : zia khan , entity2 : karachi\n",
        "\n",
        "  Input Text is : {text}\n",
        "  Classification is: {classification}\n",
        "  Output JSON Output:\n",
        "  {\"entities\": [\"1\"...]}\n",
        "  \"\"\"\n",
        "\n",
        "  output = llm.invoke(prompt.format(text=text, classification = classification))\n",
        "  return {'classification': output.content }\n"
      ],
      "metadata": {
        "id": "Mg59b_EgRyc2"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sample_state: TextAnalysisState = {\n",
        "#     'text': input_text,\n",
        "#     'classification': 'NEWS'\n",
        "# }\n",
        "\n",
        "# # text_classify(sample_state)  # Call text_classify to add classification to sample_state\n",
        "# enti_output = entities_extraction(sample_state)\n",
        "# print(enti_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "TdJGHsfDdAHT",
        "outputId": "e54f5e5b-660e-41dd-8369-93a9aeddec9c"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'input_text' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-c0e5897315a9>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m sample_state: TextAnalysisState = {\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;34m'text'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minput_text\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;34m'classification'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'NEWS'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m }\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'input_text' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# \"NODE3\"  text_summary"
      ],
      "metadata": {
        "id": "XsR1QfT48ZJm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# node 3 text summary\n",
        "\n",
        "def text_summary(state: TextAnalysisState) -> TextAnalysisState:\n",
        "  print('--summary--', state)\n",
        "  text: str = state['text']\n",
        "  classification: str = state['classification']\n",
        "  entities : List[str] = state['entities']\n",
        "\n",
        "  prompt: str = f\"\"\"\n",
        "  You will be given text and its classification as input.\n",
        "  Summarize the given text within 150 words, capturing the key information and main points.\n",
        "  Input Text: {text}\n",
        "  Classification: {classification}\n",
        "  Entities is : {entities}\n",
        "  Summary:\n",
        "  \"\"\"\n",
        "  output = llm.invoke(prompt)\n",
        "  state['summary'] = output.content.strip()\n",
        "  return state\n",
        "\n"
      ],
      "metadata": {
        "id": "wGQ-BGWuDEIQ"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from your_grok_library import GrokAI  # Replace with actual library import\n",
        "\n",
        "# # Initialize an instance of Grok AI\n",
        "# grok_ai = GrokAI(\n",
        "#     api_key=your_grok_api_key,  # Provide your Grok API key\n",
        "#     model=\"grok_model_name\"      # Specify the model to use if applicable\n",
        "# )"
      ],
      "metadata": {
        "id": "39nKqr7QWoDl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import StateGraph, START,END\n",
        "from langgraph.graph.state import CompiledStateGraph"
      ],
      "metadata": {
        "id": "mWv7xOppruvF"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the state graph\n",
        "text_analysis_builder = StateGraph(TextAnalysisState)\n",
        "\n",
        "# Add nodes to the graph with unique names\n",
        "text_analysis_builder.add_node(\"classification_node\", text_classify)\n",
        "text_analysis_builder.add_node(\"entity_extraction_node\", entities_extraction)\n",
        "text_analysis_builder.add_node(\"summarization_node\", text_summary)\n",
        "\n",
        "# Define graph edges with updated node names\n",
        "text_analysis_builder.add_edge(START, \"classification_node\")\n",
        "text_analysis_builder.add_edge(\"classification_node\", \"entity_extraction_node\")\n",
        "text_analysis_builder.add_edge(\"entity_extraction_node\", \"summarization_node\")\n",
        "text_analysis_builder.add_edge(\"summarization_node\", END)\n",
        "\n",
        "# Compile the graph (only once)\n",
        "text_analysis_compiledgraph = text_analysis_builder.compile()\n",
        "\n",
        "# Take Input from the User\n",
        "input_text = input(\"Enter text for analysis: \")\n",
        "\n",
        "# Define the initial state with user input\n",
        "state = {\n",
        "    'text': input_text,\n",
        "    'classification': '',\n",
        "    'entities': [],\n",
        "    'summary': ''\n",
        "}\n",
        "\n",
        "# Run the state graph and get the results\n",
        "result = text_analysis_compiledgraph\n",
        "\n",
        "\n",
        "# Display the results\n",
        "print(\"\\n--- Text Analysis Results ---\")\n",
        "print(f\"Classification: {result['classification']}\")\n",
        "print(f\"Entities: {result['entities']}\")\n",
        "print(f\"Summary: {result['summary']}\")"
      ],
      "metadata": {
        "id": "BqzzWw8SvCc0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "8015a263-4f74-4615-8a09-9c8571cc21a2"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter text for analysis: artificial intelligence (AI) model that uses deep learning to perform natural language processing (NLP) tasks. LLMs are trained on large amounts of data, such as text from the internet or Wikipedia, to learn statistical relationships and understand how words and phrases relate to each other. They can then be used to generate or translate text, answer questions, summarize documents, and more. LLMs are also known as neural networks (NNs) because they are computing systems inspired by the human brain.\n",
            "\n",
            "--- Text Analysis Results ---\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "'CompiledStateGraph' object is not subscriptable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-70-a7f8daa68746>\u001b[0m in \u001b[0;36m<cell line: 35>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;31m# Display the results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n--- Text Analysis Results ---\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Classification: {result['classification']}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Entities: {result['entities']}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Summary: {result['summary']}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'CompiledStateGraph' object is not subscriptable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# def text_classify(state: TextAnalysisState) -> TextAnalysisState:\n",
        "#     text : input_text = state['text'].lower()  # Convert to lowercase once\n",
        "\n",
        "#     # Classify based on keywords in the text\n",
        "#     if \"breaking news\" in text or \"report\" in text or \"headline\" in text:\n",
        "#         state['classification'] = 'News'\n",
        "#     elif \"blog\" in text or \"opinion\" in text or \"personal\" in text:\n",
        "#         state['classification'] = 'Blog'\n",
        "#     elif \"research\" in text or \"study\" in text or \"paper\" in text:\n",
        "#         state['classification'] = 'Research'\n",
        "#     else:\n",
        "#         state['classification'] = 'Other'\n",
        "\n",
        "#     print('--classification--', state['classification'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "sxh2dTaL_0fE",
        "outputId": "f8d1736f-9b56-44b8-aeb3-e79a458ac727"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'CompiledStateGraph' object has no attribute 'execute'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-54be5248ba8f>\u001b[0m in \u001b[0;36m<cell line: 22>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m }\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# Run the state graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext_analysis_compiledgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mclassification\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext_classify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'CompiledStateGraph' object has no attribute 'execute'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  sample_state variable for TextAnalysisState\n",
        "\n",
        "# sample_state: TextAnalysisState = {\n",
        "#    \"text\": \"Education in Pakistan is overseen by the Federal Ministry of Education and the provincial governments, while the federal government mostly assists in curriculum development, accreditation and the financing of research and development. 'The State shall provide free and to all children of the age of five to sixteen years in such a manner as may be determined by law'.Considering the challenges confronting the youth in Pakistan, it's hardly astonishing that well-off and educated young individuals and professionals are opting to depart the country whenever they have the opportunity, exacerbating the brain drain phenomenon.\"\n",
        "# }\n"
      ],
      "metadata": {
        "id": "p0M6xN0nJdOl"
      },
      "execution_count": 42,
      "outputs": []
    }
  ]
}
